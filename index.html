<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <link
            href="https://fonts.googleapis.com/css?family=Lato:100,300,400,700,900"
            rel="stylesheet"
    />

    <title>Anina Camara - diplomová práca</title>
    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet" />

    <!-- Additional CSS Files -->
    <link rel="stylesheet" href="assets/css/fontawesome.css" />
    <link rel="stylesheet" href="assets/css/templatemo-style.css" />
    <link rel="stylesheet" href="assets/css/owl.css" />
    <link rel="stylesheet" href="assets/css/lightbox.css" />
</head>
<body>
<div id="page-wraper">
    <!-- Sidebar Menu -->
    <div class="responsive-nav">
        <i class="fa fa-bars" id="menu-toggle"></i>
        <div id="menu" class="menu">
            <i class="fa fa-times" id="menu-close"></i>
            <div class="container">
                <div class="image">
                    <img src="assets/images/author-image.jpg" alt="author image" />
                </div>
                <div class="author-content">
                    <h4>Bc.Anna Camara</h4>
                    <span>Anina</span>
                </div>
                <nav class="main-nav" role="navigation">
                    <ul class="main-menu">
                        <li class = "active"><a href="index.html" >Diploma thesis</a></li>

                        <ul class="sub-menu">
                            <li><a href="#section1">Abstract</a></li>
                            <li><a href="#section2">Literature</a></li>
                            <li><a href="#section3">Future Plans</a></li>
                        </ul>
                        <li><a href="progress.html"  >Progress Calendar</a></li>
                        <li><a href="Diplomovka_Camara.pdf"  >Current Version</a></li>
                    </ul>
                </nav>
                <div class="copyright-text">
                    <p>Copyright 2019 Reflux Design
                        <br>
                        Adjustments 2022 Anna Camara
                    </p>
                </div>
            </div>
        </div>
    </div>
<!-- ----------------------Abstract-------------------------->
    <section class="section abstract" data-section="section1" id="section1" >
        <div class="container">
            <div class="section-heading">
                <h2>Abstract</h2>
                <div class="line-dec"></div>
                <span>Person identification with partially occluded face.</span>
                <p class="text-left"> The goal of the thesis is to identify a person in case when face is partially
                    occluded for example with sunglasses or face mask. Study the topic of person
                    identification based on the face. Analyze the performance of the existing
                    solutions published in the literature. Propose a new method based on a neural
                    network, which can find and identify a person. Create a dataset for training and
                    testing purposes. Evaluate the proposed method and draw the conclusions.</p>
            </div>
        </div>
        <div class="container">
            <div class="section-heading">
                <h2>Goals</h2>
                <div class="line-dec"></div>
                <p class="text-left">
                <ul class="ul-left">
                    <li>Learn about current approaches in face identification</li>
                    <li>Discover what is true about face identification working worse for people of color. Why and how to fix it.</li>
                    <li>Make/find more gender and race balanced database - probably merge some databases together </li>
                    <li>Focus on face occlusion by face mask.</li>
                    <li>Use face masks only in testing and validation set.</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- ----------------------Literature------------------------ -->
    <section class="section literature" data-section="section2" id="section2">
        <div class="container">
            <div class="section-heading">
                <h2>Literature</h2>
                <div class="line-dec"></div>
                <span>This is all of the literature I read to get familiar with the topic</span>
                <p class="text-left">
                <table>
                    <tr>
                        <th>Name of the article</th>
                        <th>link</th>
                        <th>Short descrition</th>
                    </tr>
                    <tr>
                        <td>DeepFace: Closing the Gap to Human-Level Performance in Face Verification</td>
                        <td><a href="https://scontent-ams4-1.xx.fbcdn.net/v/t39.8562-6/240890413_887772915161178_4705912772854439762_n.pdf?_nc_cat=109&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=GO7VpRmI1OQAX8hJHZt&_nc_ht=scontent-ams4-1.xx&oh=00_AfC4jsjAyR8kC38QCP8CNjE67ZojQiWVAj2ysG8CblJOTA&oe=63938A3F">article</a></td>
                        <td>In modern face recognition, the conventional pipeline
                            consists of four stages: detect ⇒ align ⇒ represent ⇒ classify.
                            We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to
                            apply a piecewise affine transformation, and derive a face
                            representation from a nine-layer deep neural network.</td>
                    </tr>
                    <tr>
                        <td>Face Recognition Systems: A Survey</td>
                        <td><a href="https://www.mdpi.com/1424-8220/20/2/342" target="_blank">article</a></td>
                        <td>Contribution of this survey is to review some well-known techniques for each approach
                            and to give the taxonomy of their categories. In the paper, a detailed comparison between
                            these techniques is exposed by listing the advantages and the disadvantages of their schemes
                            in terms of robustness, accuracy, complexity, and discrimination</td>
                    </tr>
                    <tr>
                        <td>Thales: Facial recognition: top 7 trends (tech, vendors, use cases)</td>
                        <td><a href="https://www.thalesgroup.com/en/markets/digital-identity-and-security/government/biometrics/facial-recognition" target="_blank">website</a></td>
                        <td>Overview on current facial recognition techniques</td>
                    </tr>
                    <tr>
                        <td>Biometrics Institute: What is Biometrics?</td>
                        <td><a href="https://www.biometricsinstitute.org/what-is-biometrics/" target="_blank">website</a></td>
                        <td>Definition of biometrics</td>
                    </tr>
                    <tr>
                        <td>Biometrics Institute: Types of Biometrics: Face – Use Cases</td>
                        <td><a href="https://www.biometricsinstitute.org/types-of-biometrics-face-use-cases/" target="_blank">website</a></td>
                        <td>Examples of face verification and identification.</td>
                    </tr>
                    <tr>
                        <td>Past, Present, and Future of Face Recognition: A Review</td>
                        <td><a href="https://www.mdpi.com/2079-9292/9/8/1188" target="_blank">article</a></td>
                        <td>This review presents the history of face recognition technology, the current
                            state-of-the-art methodologies, and future directions. We specifically concentrate on
                            the most recent databases, 2D and 3D face recognition methods.</td>
                    </tr>
                    <tr>
                        <td>An anatomical and photographic technique for forensic facial identification</td>
                        <td><a href="https://www-sciencedirect-com.proxy.library.uu.nl/science/article/pii/S0379073800002905" target="_blank">article</a></td>
                        <td>This paper describes a photographic technique which allows accurate anatomical measurement
                            and tracing of facial features, which allows direct physical comparison of ID document images.</td>
                    </tr>
                    <tr>
                        <td>ISO/IEC 2382-37:2022(en) Information technology — Vocabulary — Part 37: Biometrics</td>
                        <td><a href="https://www.iso.org/obp/ui/#iso:std:iso-iec:2382:-37:ed-3:v1:en:term:37.08.03" target="_blank">website</a></td>
                        <td>Definition of biometrics.</td>
                    </tr>
                    <tr>
                        <td>FaceFilter: Face Identification with Deep Learning and Filter Algorithm</td>
                        <td><a href="https://www.hindawi.com/journals/sp/2020/7846264/" target="_blank"> article </a></td>
                        <td>In this study, we present a system that can directly identify an individual under all
                            conditions (faces are in different poses or have different levels of illumination,
                            or when the face is blurred) by extracting the most important features and using them to
                            identify a person. Our method uses a deep convolutional network that is trained to extract
                            the most important features. A filter is then used to ...</td>
                    </tr>
                    <tr>
                        <td> Masked face identification is improved by diagnostic feature training </td>
                        <td><a href="https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-022-00381-x#citeas"
                                                   target="_blank">article</a></td>
                        <td>Human performance</td>
                    </tr>
                    <tr>
                        <td>Face Recognition Performance: Role of Demographic Information</td>
                        <td><a href="https://www.researchgate.net/publication/260299859_Face_Recognition_Performance_Role_of_Demographic_Information" target="_blank">article </a></td>
                        <td>This paper studies the influence of demographics on the performance of face recognition
                            algorithms. The recognition accuracies of six different face recognition algorithms
                            (three commercial, two nontrainable, and one trainable) are computed on a large scale
                            gallery that is partitioned so that each partition consists entirely of specific demographic cohorts. </td>
                    </tr>
                    <tr>
                        <td>Gender Shades: Intersectional Accuracy Disparities in
                            Commercial Gender Classification</td>
                        <td><a href="http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf" target="_blank"> article </a></td>
                        <td>In this work, we present an approach to evaluate bias present in automated facial analysis
                            algorithms and datasets with respect to phenotypic subgroups</td>
                    </tr>
                    <tr>
                        <td>Is facial recognition technology worse at identifying darker-skinned faces than lighter ones?</td>
                        <td><a href="https://www.abc.net.au/news/2020-02-04/fact-check-facial-recognition-darker-skin/11781192?nw=0&r=Interactive" target="_blank">article</a></td>
                        <td>Commercial article - ...</td>
                    </tr>

                </table>
            </div>
        </div>
    </section>
    
        <section class="section plany" data-section="section3" id="section3" >
        <div class="container">
            <div class="section-heading">
                <h2>Future plans</h2>
                <div class="line-dec"></div>
                <span>To do list. What I am planning to read or what I'mm planning to get back to.</span>
                <p class="text-left">
                <ul class="ul-left">
                    <li>read the paper about database <a href="https://github.com/joojs/fairface">FairFace</a> </li>
                    <li>learn about <a href = "https://arxiv.org/pdf/1503.03832.pdf">FaceNet</a> and <a href = "https://github.com/akshaybahadur21/Facial-Recognition-using-Facenet">models using it</a></li>
                    <li>learn about <a href = "https://github.com/TadasBaltrusaitis/OpenFace">OpenFace</a> </li>
                    <li>learn about triplet loss function</li>
                    <li>learn about face recognition without triplet loss function like they do in <a href = "https://www.hindawi.com/journals/sp/2020/7846264/"> here </a></li>
                    <li>learn about current face recognition systems - analyse their performance on masked faces and write a chpter about it <li>
                </ul>
            </div>
        </div>
    </section>

</div>
<script src="vendor/jquery/jquery.min.js"></script>
<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

<script src="assets/js/isotope.min.js"></script>
<script src="assets/js/owl-carousel.js"></script>
<script src="assets/js/lightbox.js"></script>
<script src="assets/js/custom.js"></script>
<script>
    //according to loftblog tut
    // $(".main-menu li:first").addClass("active");

    var showSection = function showSection(section, isAnimate) {
        var direction = section.replace(/#/, ""),
            reqSection = $(".section").filter(
                '[data-section="' + direction + '"]'
            ),
            reqSectionPos = reqSection.offset().top - 0;

        if (isAnimate) {
            $("body, html").animate(
                {
                    scrollTop: reqSectionPos
                },
                800
            );
        } else {
            $("body, html").scrollTop(reqSectionPos);
        }
    };

    var checkSection = function checkSection() {
        $(".section").each(function() {
            var $this = $(this),
                topEdge = $this.offset().top - 80,
                bottomEdge = topEdge + $this.height(),
                wScroll = $(window).scrollTop();

            if (topEdge < wScroll && bottomEdge > wScroll) {
                var currentId = $this.data("section"),
                    reqLink = $("a").filter("[href*=\\#" + currentId + "]");
                reqLink
                    .closest("li")
                    .addClass("active")
                    .siblings()
                    .removeClass("active");
            }
        });
    };

    $(".sub-menu").on("click", "a", function(e) {
        e.preventDefault();
        showSection($(this).attr("href"), true);
    });

    $(window).scroll(function() {
        checkSection();
    });
</script>
</body>
</html>
